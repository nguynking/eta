{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as L\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import modal\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_frame as tf\n",
    "from torch_frame.data import Dataset\n",
    "from torch_frame.utils import infer_df_stype\n",
    "from torch_frame.data.loader import DataLoader\n",
    "from torch_frame.nn.encoder import EmbeddingEncoder, LinearEncoder\n",
    "from torch_frame.nn.models import FTTransformer\n",
    "from torchmetrics import Accuracy, MeanAbsoluteError\n",
    "\n",
    "# Modal app\n",
    "app        = modal.App(\"parcel-hp-sweep\")\n",
    "MINUTES     = 60\n",
    "HOURS       = 60 * MINUTES\n",
    "GPU_TYPE    = \"T4\"\n",
    "vol         = modal.Volume.from_name(\"parcel\", create_if_missing=True)\n",
    "VPATH       = PosixPath(\"/vol\")\n",
    "MODEL_DIR   = VPATH / \"models\"\n",
    "\n",
    "# container images\n",
    "base_image  = modal.Image.debian_slim(python_version=\"3.11\").uv_pip_install(\n",
    "    \"duckdb\", \"pyarrow\", \"pandas\", \"numpy\"\n",
    ")\n",
    "torch_image = (\n",
    "    base_image\n",
    "    .uv_pip_install(\n",
    "        \"torch\",\n",
    "        \"torch_frame\",\n",
    "        \"torchmetrics\",\n",
    "        \"wandb\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# helpers\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "@dataclass\n",
    "class HParams:\n",
    "    # model\n",
    "    channels: int        = 32\n",
    "    n_layers: int        = 3\n",
    "    # optimisation\n",
    "    lr: float            = 1e-2\n",
    "    # dataset\n",
    "    sample_rows: int     = 10\n",
    "    batch_size: int      = 5\n",
    "    val_split: float     = 0.2\n",
    "    seed: int            = 42\n",
    "\n",
    "# data module\n",
    "def build_dataloaders(\n",
    "    parquet_path: str,\n",
    "    target_col: str,\n",
    "    task: str,\n",
    "    h: HParams,\n",
    ") -> Tuple[DataLoader, DataLoader, tf.data.Dataset.col_stats, dict]:\n",
    "    \"\"\"\n",
    "    Returns train & val DataLoaders plus col_stats / col_names_dict needed by model.\n",
    "    `task` ∈ {\"regression\", \"binary\"}\n",
    "    \"\"\"\n",
    "    q = f\"SELECT * FROM '{parquet_path}'\"\n",
    "    if h.sample_rows:\n",
    "        q += f\" USING SAMPLE reservoir({h.sample_rows} ROWS) REPEATABLE ({h.seed})\"\n",
    "    df = duckdb.sql(q).df()\n",
    "\n",
    "    if task == \"regression\":\n",
    "        df[target_col] = df[target_col].astype(float)\n",
    "    else:\n",
    "        df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    # simple heuristic – drop obvious identifiers\n",
    "    df = df.drop(columns=[c for c in df.columns if c.endswith(\"_id\")], errors=\"ignore\")\n",
    "\n",
    "    col2stype = infer_df_stype(df)\n",
    "    col2stype[target_col] = tf.numerical if task == \"regression\" else tf.categorical\n",
    "\n",
    "    full_ds = Dataset(df, col_to_stype=col2stype, target_col=target_col)\n",
    "    n_train = int(len(full_ds) * (1 - h.val_split))\n",
    "    train_ds, val_ds = full_ds[:n_train], full_ds[n_train:]\n",
    "\n",
    "    train_ds.materialize(path=f\"{VPATH}/train_stats.pt\")\n",
    "    val_ds.materialize(path=f\"{VPATH}/val_stats.pt\", col_stats=train_ds.col_stats)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=h.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=h.batch_size)\n",
    "\n",
    "    return train_loader, val_loader, train_ds.col_stats, train_ds.tensor_frame.col_names_dict\n",
    "\n",
    "# training loop\n",
    "def run_epoch(\n",
    "    model, loader, optim, criterion, device\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total = n = 0.0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred  = model(batch).squeeze()\n",
    "        loss  = criterion(pred, batch.y.float())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += loss.item() * len(batch.y)\n",
    "        n += len(batch.y)\n",
    "    return total / n\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, metric, device) -> float:\n",
    "    metric.reset()\n",
    "    model.eval()\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred  = model(batch).squeeze()\n",
    "        if isinstance(metric, Accuracy):\n",
    "            pred = torch.sigmoid(pred)\n",
    "        metric.update(pred, batch.y.float())\n",
    "    return metric.compute().item()\n",
    "\n",
    "# remote fn\n",
    "@app.function(\n",
    "    gpu=GPU_TYPE,\n",
    "    image=torch_image,\n",
    "    timeout=2 * HOURS,\n",
    "    volumes={VPATH: vol},\n",
    "    secrets=[modal.Secret.from_name(\"wandb-secret\")]\n",
    ")\n",
    "def train_model(\n",
    "    parquet_path: str,\n",
    "    target_col: str,\n",
    "    task: str,\n",
    "    h: HParams,\n",
    "    run_to_end: bool,\n",
    "    max_epochs: int = 50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train one model with given hyper-parameters.\n",
    "    \"\"\"\n",
    "    set_seed(h.seed)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # data\n",
    "    train_loader, val_loader, col_stats, col_names_dict = build_dataloaders(\n",
    "        parquet_path, target_col, task, h\n",
    "    )\n",
    "\n",
    "    # model\n",
    "    enc = {\n",
    "        tf.stype.categorical: EmbeddingEncoder(),\n",
    "        tf.stype.numerical:   LinearEncoder(),\n",
    "    }\n",
    "    model = FTTransformer(\n",
    "        channels=h.channels,\n",
    "        num_layers=h.n_layers,\n",
    "        out_channels=1,\n",
    "        col_stats=col_stats,\n",
    "        col_names_dict=col_names_dict,\n",
    "        stype_encoder_dict=enc,\n",
    "    )\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    # optimisation\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=h.lr)\n",
    "    criterion = torch.nn.SmoothL1Loss() if task == \"regression\" else torch.nn.BCEWithLogitsLoss()\n",
    "    metric    = MeanAbsoluteError().to(device) if task == \"regression\" else Accuracy(task=\"binary\").to(device)\n",
    "\n",
    "    # W&B\n",
    "    import wandb\n",
    "    wandb.init(\n",
    "        project=\"parcel-tabular\",\n",
    "        config=dict(**h.__dict__, task=task),\n",
    "        name=f\"E{datetime.now().strftime('%m%d_%H%M%S')}_ch{h.channels}_L{h.n_layers}_lr{h.lr:g}\",\n",
    "    )\n",
    "    best_val, patience, PATIENCE = (np.inf if task==\"regression\" else 0.0), 0, 5\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        tr_loss = run_epoch(model, train_loader, optim, criterion, device)\n",
    "        val_metric = evaluate(model, val_loader, metric, device)\n",
    "        wandb.log({\"epoch\": epoch, \"train_loss\": tr_loss,\n",
    "                   \"val_metric\": val_metric})\n",
    "\n",
    "        improved = (val_metric < best_val) if task==\"regression\" else (val_metric > best_val)\n",
    "        if improved:\n",
    "            best_val, patience = val_metric, 0\n",
    "            # save weights into the shared Volume so other jobs can see them\n",
    "            MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(model.state_dict(), MODEL_DIR / f\"{wandb.run.name}.pt\")\n",
    "            vol.commit()\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE and not run_to_end:\n",
    "                break\n",
    "    wandb.finish()\n",
    "    return float(best_val)\n",
    "\n",
    "# sweep main\n",
    "@app.local_entrypoint()\n",
    "def main(\n",
    "    parquet_path: str = \"../data/parcel_tracking_output_data.parquet\",\n",
    "    target_col: str   = \"total_hours_from_receiving_to_last_success_delivery\",\n",
    "    task: str         = \"regression\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Kick off an 8-run grid search, find the best, then resume it to completion.\n",
    "    \"\"\"\n",
    "    # default hparams\n",
    "    ref = HParams()\n",
    "    ch_opts  = (16, ref.channels)\n",
    "    lyr_opts = (2,  ref.n_layers)\n",
    "    lr_opts  = (1e-3, ref.lr)\n",
    "\n",
    "    hp_list: List[HParams] = [\n",
    "        HParams(channels=channel, n_layers=layer, lr=lr,\n",
    "                sample_rows=ref.sample_rows,\n",
    "                batch_size=ref.batch_size,\n",
    "                val_split=ref.val_split,\n",
    "                seed=42)\n",
    "        for channel, layer, lr in product(ch_opts, lyr_opts, lr_opts)\n",
    "    ]\n",
    "\n",
    "    print(f\"Launching {len(hp_list)} hyper-param jobs on Modal …\")\n",
    "    # first round – early stop\n",
    "    early_results = train_model.starmap(\n",
    "        [\n",
    "            (parquet_path, target_col, task, h, False)   # run_to_end=False\n",
    "            for h in hp_list\n",
    "        ],\n",
    "        order_outputs=False,\n",
    "    )\n",
    "\n",
    "    best_h, best_val = None, np.inf if task==\"regression\" else -np.inf\n",
    "    for res, h in zip(early_results, hp_list):\n",
    "        v = float(res)\n",
    "        better = (v < best_val) if task==\"regression\" else (v > best_val)\n",
    "        print(f\"{h} ⇒ {v:.4f}\")\n",
    "        if better:\n",
    "            best_h, best_val = h, v\n",
    "\n",
    "    print(f\"\\nBest so far: {best_h} ({best_val:.4f}) — continuing to full training …\")\n",
    "    # train_model.remote(parquet_path, target_col, task, best_h, True, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfa8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4d104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabular_experiments.py\n",
    "# Re‑usable pipeline for ETA regression & POD classification\n",
    "import argparse\n",
    "import random\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import torch\n",
    "# import torch.nn.functional as F\n",
    "import torch_frame as tf\n",
    "from torch_frame.data import Dataset\n",
    "from torch_frame.utils import infer_df_stype\n",
    "from torch_frame.data.loader import DataLoader\n",
    "from torchmetrics import Accuracy, MeanAbsoluteError   # torchmetrics ≥1.4\n",
    "from torch_frame.nn.encoder import EmbeddingEncoder, LinearEncoder\n",
    "from torch_frame.nn.models import FTTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6757fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 100 % reproducibility\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 1. Data module (handles leakage‑free materialisation)\n",
    "class TabularDataModule:\n",
    "    def __init__(self, file_path: str, target: str, task: str,\n",
    "                 sample_rows: int = None, batch_size: int = 256,\n",
    "                 val_split: float = 0.2, seed: int = 42):\n",
    "        \"\"\"\n",
    "        task ∈ {\"regression\", \"binary\"}\n",
    "        \"\"\"\n",
    "        self.file_path, self.target, self.task = file_path, target, task\n",
    "        self.sample_rows, self.batch_size, self.val_split, self.seed = \\\n",
    "            sample_rows, batch_size, val_split, seed\n",
    "\n",
    "    def load(self):\n",
    "        q = f\"SELECT * FROM '{self.file_path}'\"\n",
    "        if self.sample_rows:\n",
    "            q += f\" USING SAMPLE reservoir({self.sample_rows} ROWS) REPEATABLE ({self.seed})\"\n",
    "        df = duckdb.sql(q).df()\n",
    "\n",
    "        # Cast target dtype & drop high‑cardinality IDs\n",
    "        if self.task == \"regression\":\n",
    "            df[self.target] = df[self.target].astype(float)\n",
    "        else:\n",
    "            df[self.target] = df[self.target].astype(int)\n",
    "        df = df.drop(columns=[\"customer_id\", \"parcel_id\"], errors=\"ignore\")\n",
    "\n",
    "        # Detect column semantics *before* split\n",
    "        col_to_stype = infer_df_stype(df)\n",
    "        col_to_stype[self.target] = tf.numerical if self.task == \"regression\" else tf.categorical\n",
    "\n",
    "        # Create Dataset & materialise **train only** to avoid leakage\n",
    "        ds = Dataset(df, col_to_stype=col_to_stype, target_col=self.target)\n",
    "        n_train = int(len(ds) * (1 - self.val_split))\n",
    "        train_ds, val_ds = ds[:n_train], ds[n_train:]\n",
    "        train_ds.materialize(path=\"cache/train.pt\")             # persisted stats\n",
    "        val_ds.materialize(path=\"cache/val.pt\", col_stats=train_ds.col_stats)\n",
    "\n",
    "        # Mini‑batch loaders\n",
    "        self.train_loader = DataLoader(train_ds, batch_size=self.batch_size, shuffle=True)\n",
    "        self.val_loader   = DataLoader(val_ds,   batch_size=self.batch_size)\n",
    "\n",
    "        self.col_stats, self.col_names_dict = train_ds.col_stats, train_ds.tensor_frame.col_names_dict\n",
    "\n",
    "\n",
    "# 2. Model factory (drop your own backbones here)\n",
    "def build_model(name: str, out_channels: int,\n",
    "                col_stats, col_names_dict, stype_enc):\n",
    "    if name == \"ftt\":\n",
    "        return FTTransformer(channels=32, out_channels=out_channels,\n",
    "                             num_layers=4,\n",
    "                             col_stats=col_stats,\n",
    "                             col_names_dict=col_names_dict,\n",
    "                             stype_encoder_dict=stype_enc)\n",
    "    elif name == \"mlp\":        # tiny baseline for sanity checks\n",
    "        from torch_frame.nn.models import MLP\n",
    "        return MLP(channels=64, out_channels=out_channels,\n",
    "                   col_stats=col_stats,\n",
    "                   col_names_dict=col_names_dict,\n",
    "                   stype_encoder_dict=stype_enc)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model {name}\")\n",
    "\n",
    "\n",
    "# 3. Generic trainer\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        pred = model(batch).squeeze()\n",
    "        y = batch.y.float()\n",
    "        loss = criterion(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item() * len(y)\n",
    "        n += len(y)\n",
    "    return loss_sum / n\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    for batch in loader:\n",
    "        pred = model(batch).squeeze()\n",
    "        y = batch.y.float()\n",
    "        if isinstance(metric, Accuracy):\n",
    "            pred = torch.sigmoid(pred)\n",
    "        metric.update(pred, y)\n",
    "    return metric.compute().item()\n",
    "\n",
    "\n",
    "# 4. Experiment runner\n",
    "def run(args):\n",
    "    set_seed(args.seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Build data\n",
    "    dm = TabularDataModule(args.file, args.target, args.task,\n",
    "                           sample_rows=args.sample, batch_size=args.batch,\n",
    "                           val_split=args.val_split, seed=args.seed)\n",
    "    dm.load()\n",
    "\n",
    "    # Shared stype encoders\n",
    "    stype_enc = {tf.stype.categorical: EmbeddingEncoder(),\n",
    "                 tf.stype.numerical:   LinearEncoder()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Model & optimiser\n",
    "    out_dim = 1    # both tasks output scalar\n",
    "    model = build_model(args.model, out_dim,\n",
    "                        dm.col_stats, dm.col_names_dict, stype_enc).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Loss & metric\n",
    "    if args.task == \"regression\":\n",
    "        criterion = torch.nn.SmoothL1Loss()\n",
    "        metric = MeanAbsoluteError().to(device)\n",
    "    else:\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        metric = Accuracy(task=\"binary\").to(device)\n",
    "\n",
    "    # Training loop with rudimentary early stopping\n",
    "    best_val, patience = float(\"inf\") if args.task == \"regression\" else 0.0, 0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        tr_loss = train(model, dm.train_loader, opt, criterion)\n",
    "        val_metric = evaluate(model, dm.val_loader, metric)\n",
    "        print(f\"E{epoch:02d} | train-loss {tr_loss:.4f} | val‑{'MAE' if args.task == 'regression' else 'Acc'} {val_metric:.4f}\")\n",
    "        improve = (val_metric < best_val) if args.task == \"regression\" else (val_metric > best_val)\n",
    "        if improve:\n",
    "            best_val, patience = val_metric, 0\n",
    "            torch.save(model.state_dict(), \"best.pt\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= args.patience:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89dd1b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run() missing 1 required positional argument: 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: run() missing 1 required positional argument: 'args'"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc796003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CLI – define once; compare infinitely\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--file\",   type=str, required=True)\n",
    "    p.add_argument(\"--target\", type=str, required=True)\n",
    "    p.add_argument(\"--task\",   choices=[\"regression\", \"binary\"], required=True)\n",
    "    p.add_argument(\"--model\",  choices=[\"ftt\", \"mlp\"], default=\"ftt\")\n",
    "    p.add_argument(\"--sample\", type=int, default=None)\n",
    "    p.add_argument(\"--batch\",  type=int, default=256)\n",
    "    p.add_argument(\"--lr\",     type=float, default=5e-3)\n",
    "    p.add_argument(\"--epochs\", type=int, default=50)\n",
    "    p.add_argument(\"--val_split\", type=float, default=0.2)\n",
    "    p.add_argument(\"--patience\",  type=int, default=5)\n",
    "    p.add_argument(\"--seed\",      type=int, default=42)\n",
    "    # run(p.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8ec46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_frame as tf\n",
    "from torch_frame.data import Dataset\n",
    "from torch_frame.utils import infer_df_stype\n",
    "from torch_frame.data.loader import DataLoader\n",
    "from torch_frame.nn.encoder import EmbeddingEncoder, LinearEncoder\n",
    "from torch_frame.nn.models import FTTransformer   # any backbone works\n",
    "\n",
    "# 1. Read & sample exactly the same way you did\n",
    "file_path = \"../data/parcel_tracking_output_data.parquet\"\n",
    "df = duckdb.sql(f\"\"\"\n",
    "    SELECT * FROM '{file_path}'\n",
    "    USING SAMPLE reservoir(100 ROWS)\n",
    "    REPEATABLE (100)\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1fc329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import duckdb\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import torch_frame as tf\n",
    "# from torch_frame.data import Dataset\n",
    "# from torch_frame.utils import infer_df_stype\n",
    "# from torch_frame.data.loader import DataLoader\n",
    "# from torch_frame.nn.encoder import EmbeddingEncoder, LinearEncoder\n",
    "# from torch_frame.nn.models import FTTransformer   # any backbone works\n",
    "\n",
    "# # 1. Read & sample exactly the same way you did\n",
    "# file_path = \"../data/parcel_tracking_output_data.parquet\"\n",
    "# df = duckdb.sql(f\"\"\"\n",
    "#     SELECT * FROM '{file_path}'\n",
    "#     USING SAMPLE reservoir(100 ROWS)\n",
    "#     REPEATABLE (100)\n",
    "# \"\"\").df()\n",
    "\n",
    "# # Targets ----------------------------------------------------\n",
    "# ETA_COL   = \"total_hours_from_receiving_to_last_success_delivery\"\n",
    "# POD_COL   = \"is_successful_delivery\"\n",
    "\n",
    "# # Cast targets to numeric\n",
    "# df[ETA_COL] = df[ETA_COL].astype(float)\n",
    "# df[POD_COL] = df[POD_COL].astype(int)\n",
    "# df.drop(columns=[\"customer_id\", \"parcel_id\"], inplace=True)\n",
    "\n",
    "# eta_df = df.drop(columns=[POD_COL])\n",
    "# pod_df = df.drop(columns=[ETA_COL])\n",
    "\n",
    "# # 2. Build two Dataset objects (one per task)\n",
    "# eta_col_to_stype = infer_df_stype(eta_df)\n",
    "# eta_col_to_stype[ETA_COL] = tf.numerical\n",
    "\n",
    "# pod_col_to_stype = infer_df_stype(pod_df)\n",
    "# pod_col_to_stype[POD_COL] = tf.categorical\n",
    "\n",
    "# eta_ds = Dataset(eta_df, col_to_stype=eta_col_to_stype, target_col=ETA_COL)\n",
    "# pod_ds = Dataset(pod_df, col_to_stype=pod_col_to_stype, target_col=POD_COL)\n",
    "\n",
    "# # Materialise once so we can reuse stats & mappings\n",
    "# eta_ds.materialize()              # gives .tensor_frame, .col_stats\n",
    "# pod_ds.materialize()\n",
    "\n",
    "# # Split\n",
    "# train_eta = eta_ds[:0.8]    # same slice trick as in quick‑tour :contentReference[oaicite:3]{index=3}\n",
    "# val_eta   = eta_ds[0.8:]\n",
    "# train_pod = pod_ds[:0.8]\n",
    "# val_pod   = pod_ds[0.8:]\n",
    "\n",
    "# # 3.  Mini‑batch loaders\n",
    "# BATCH = 5\n",
    "# train_eta_loader = DataLoader(train_eta, batch_size=BATCH, shuffle=True)\n",
    "# val_eta_loader   = DataLoader(val_eta,   batch_size=BATCH)\n",
    "\n",
    "# train_pod_loader = DataLoader(train_pod, batch_size=BATCH, shuffle=True)\n",
    "# val_pod_loader   = DataLoader(val_pod,   batch_size=BATCH)\n",
    "\n",
    "# # 4. Common stype‑wise encoders\n",
    "# stype_enc = {\n",
    "#     tf.stype.categorical: EmbeddingEncoder(),\n",
    "#     tf.stype.numerical:   LinearEncoder(),\n",
    "# }\n",
    "\n",
    "# # 5‑A. ETA regressor  (FT‑Transformer, 1 output)\n",
    "# eta_model = FTTransformer(\n",
    "#     channels=32,\n",
    "#     out_channels=1,\n",
    "#     num_layers=3,\n",
    "#     col_stats=train_eta.col_stats,\n",
    "#     col_names_dict=train_eta.tensor_frame.col_names_dict,\n",
    "#     stype_encoder_dict=stype_enc,\n",
    "# )\n",
    "# opt_eta = torch.optim.AdamW(eta_model.parameters(), lr=5e-3)\n",
    "\n",
    "# # 5‑B. POD classifier (same backbone, sigmoid output)\n",
    "# pod_model = FTTransformer(\n",
    "#     channels=32,\n",
    "#     out_channels=1,\n",
    "#     num_layers=3,\n",
    "#     col_stats=train_pod.col_stats,\n",
    "#     col_names_dict=train_pod.tensor_frame.col_names_dict,\n",
    "#     stype_encoder_dict=stype_enc,\n",
    "# )\n",
    "# opt_pod = torch.optim.AdamW(pod_model.parameters(), lr=1e-3)\n",
    "\n",
    "# # 6. Plain PyTorch training loops (no Lightning/Rich headaches)\n",
    "# def train_epoch(model, loader, optimizer, is_regression: bool):\n",
    "#     model.train()\n",
    "#     total = 0\n",
    "#     loss_sum = 0\n",
    "#     loss_history = []\n",
    "#     for tf_batch in loader:\n",
    "#         pred = model(tf_batch)\n",
    "#         target = tf_batch.y.float()\n",
    "#         loss = F.smooth_l1_loss(pred.squeeze(), target) if is_regression else F.binary_cross_entropy_with_logits(pred.squeeze(), target)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         loss_history.append(loss.item())\n",
    "#         loss_sum += loss.item() * len(target)\n",
    "#         total += len(target)\n",
    "#     return loss_sum / total, loss_history\n",
    "\n",
    "# for epoch in range(1, 30):\n",
    "#     eta_loss, eta_loss_history = train_epoch(eta_model, train_eta_loader, opt_eta, True)\n",
    "#     pod_loss, pod_loss_history = train_epoch(pod_model, train_pod_loader, opt_pod, False)\n",
    "#     print(f\"Epoch {epoch:02d} | ETA MAE-ish {eta_loss:.3f} | POD BCE {pod_loss:.3f}\")\n",
    "\n",
    "# # 7.  Validation & inference# -----------------------------------------------------------\n",
    "# @torch.no_grad()\n",
    "# def evaluate(model, loader, is_regression):\n",
    "#     model.eval()\n",
    "#     outs, ys = [], []\n",
    "#     for tf_batch in loader:\n",
    "#         outs.append(model(tf_batch).cpu())\n",
    "#         ys.append(tf_batch.y.float().cpu())\n",
    "#     pred = torch.cat(outs).squeeze()\n",
    "#     y    = torch.cat(ys).squeeze()\n",
    "#     if is_regression:\n",
    "#         return torch.mean(torch.abs(pred - y)).item()      # MAE\n",
    "#     else:\n",
    "#         prob = torch.sigmoid(pred)\n",
    "#         acc  = ((prob > 0.5) == y.bool()).float().mean()\n",
    "#         return acc.item()\n",
    "\n",
    "# print(\"ETA MAE (val):\", evaluate(eta_model, val_eta_loader, True))\n",
    "# print(\"POD ACC (val):\", evaluate(pod_model, val_pod_loader, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25290bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# pod_model.train()\n",
    "# loss_history = []\n",
    "# for epoch in range(0, 50):\n",
    "#     print(\"\")\n",
    "#     print(f\"EPOCH {epoch}:\")\n",
    "#     for idx, batch in enumerate(train_pod_loader):\n",
    "#         print(batch)\n",
    "#         pred = pod_model(batch)\n",
    "#         target = batch.y.float()\n",
    "#         loss = F.smooth_l1_loss(pred.squeeze(), target) if False else F.binary_cross_entropy_with_logits(pred.squeeze(), target)\n",
    "#         opt_eta.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt_eta.step()\n",
    "#         loss_history.append(loss.item())\n",
    "#         print(f\"step {idx}: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | ETA MAE-ish 24.736 | POD BCE 0.581\n",
      "Epoch 02 | ETA MAE-ish 23.274 | POD BCE 0.405\n",
      "Epoch 03 | ETA MAE-ish 21.756 | POD BCE 0.373\n",
      "Epoch 04 | ETA MAE-ish 19.835 | POD BCE 0.331\n",
      "Epoch 05 | ETA MAE-ish 17.341 | POD BCE 0.270\n",
      "Epoch 06 | ETA MAE-ish 14.937 | POD BCE 0.244\n",
      "Epoch 07 | ETA MAE-ish 13.276 | POD BCE 0.174\n",
      "Epoch 08 | ETA MAE-ish 13.048 | POD BCE 0.224\n",
      "Epoch 09 | ETA MAE-ish 12.977 | POD BCE 0.166\n",
      "Epoch 10 | ETA MAE-ish 12.933 | POD BCE 0.211\n",
      "Epoch 11 | ETA MAE-ish 13.068 | POD BCE 0.137\n",
      "Epoch 12 | ETA MAE-ish 12.984 | POD BCE 0.110\n",
      "Epoch 13 | ETA MAE-ish 13.015 | POD BCE 0.104\n",
      "Epoch 14 | ETA MAE-ish 12.997 | POD BCE 0.105\n",
      "Epoch 15 | ETA MAE-ish 12.969 | POD BCE 0.080\n",
      "Epoch 16 | ETA MAE-ish 12.974 | POD BCE 0.073\n",
      "Epoch 17 | ETA MAE-ish 12.979 | POD BCE 0.066\n",
      "Epoch 18 | ETA MAE-ish 12.965 | POD BCE 0.067\n",
      "Epoch 19 | ETA MAE-ish 13.057 | POD BCE 0.063\n",
      "Epoch 20 | ETA MAE-ish 12.859 | POD BCE 0.060\n",
      "Epoch 21 | ETA MAE-ish 12.922 | POD BCE 0.060\n",
      "Epoch 22 | ETA MAE-ish 12.936 | POD BCE 0.055\n",
      "Epoch 23 | ETA MAE-ish 12.969 | POD BCE 0.058\n",
      "Epoch 24 | ETA MAE-ish 12.953 | POD BCE 0.056\n",
      "Epoch 25 | ETA MAE-ish 12.939 | POD BCE 0.056\n",
      "Epoch 26 | ETA MAE-ish 13.011 | POD BCE 0.054\n",
      "Epoch 27 | ETA MAE-ish 12.925 | POD BCE 0.049\n",
      "Epoch 28 | ETA MAE-ish 12.959 | POD BCE 0.055\n",
      "Epoch 29 | ETA MAE-ish 12.888 | POD BCE 0.052\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(1, 30):\n",
    "#     eta_loss, eta_loss_history = train_epoch(eta_model, train_eta_loader, opt_eta, True)\n",
    "#     pod_loss, pod_loss_history = train_epoch(pod_model, train_pod_loader, opt_pod, False)\n",
    "#     print(f\"Epoch {epoch:02d} | ETA MAE-ish {eta_loss:.3f} | POD BCE {pod_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec3249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA MAE (val): 24.087116241455078\n",
      "POD ACC (val): 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "# # 7.  Validation & inference# -----------------------------------------------------------\n",
    "# @torch.no_grad()\n",
    "# def evaluate(model, loader, is_regression):\n",
    "#     model.eval()\n",
    "#     outs, ys = [], []\n",
    "#     for tf_batch in loader:\n",
    "#         outs.append(model(tf_batch).cpu())\n",
    "#         ys.append(tf_batch.y.float().cpu())\n",
    "#     pred = torch.cat(outs).squeeze()\n",
    "#     y    = torch.cat(ys).squeeze()\n",
    "#     if is_regression:\n",
    "#         return torch.mean(torch.abs(pred - y)).item()      # MAE\n",
    "#     else:\n",
    "#         prob = torch.sigmoid(pred)\n",
    "#         acc  = ((prob > 0.5) == y.bool()).float().mean()\n",
    "#         return acc.item()\n",
    "\n",
    "# print(\"ETA MAE (val):\", evaluate(eta_model, val_eta_loader, True))\n",
    "# print(\"POD ACC (val):\", evaluate(pod_model, val_pod_loader, False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
