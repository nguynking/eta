{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1fc329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc78e51a05124d1788784de837e069f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_frame as tf\n",
    "from torch_frame.data import Dataset\n",
    "from torch_frame.utils import infer_df_stype\n",
    "from torch_frame.data.loader import DataLoader\n",
    "from torch_frame.nn.encoder import EmbeddingEncoder, LinearEncoder\n",
    "from torch_frame.nn.models import FTTransformer   # any backbone works\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1.  Read & sample exactly the same way you did\n",
    "# -----------------------------------------------------------\n",
    "file_path = \"../data/parcel_tracking_output_data.parquet\"    # (or .xlsx → convert once)\n",
    "df = duckdb.sql(f\"\"\"\n",
    "    SELECT * FROM '{file_path}'\n",
    "    USING SAMPLE reservoir(100 ROWS)\n",
    "    REPEATABLE (100)\n",
    "\"\"\").df()\n",
    "\n",
    "# Targets ----------------------------------------------------\n",
    "ETA_COL   = \"total_hours_from_receiving_to_last_success_delivery\"\n",
    "POD_COL   = \"is_successful_delivery\"\n",
    "\n",
    "# Cast targets to numeric\n",
    "df[ETA_COL] = df[ETA_COL].astype(float)\n",
    "df[POD_COL] = df[POD_COL].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20f5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2.  Build two Dataset objects (one per task)\n",
    "# -----------------------------------------------------------\n",
    "col_to_stype = infer_df_stype(df)                           # auto‑detect stypes\n",
    "col_to_stype[ETA_COL] = tf.numerical                       # overwrite to be safe\n",
    "col_to_stype[POD_COL] = tf.categorical                     # binary → categorical\n",
    "\n",
    "eta_ds = Dataset(df, col_to_stype=col_to_stype,\n",
    "                 target_col=ETA_COL)\n",
    "pod_ds = Dataset(df, col_to_stype=col_to_stype,\n",
    "                 target_col=POD_COL)\n",
    "\n",
    "# Materialise once so we can reuse stats & mappings\n",
    "eta_ds.materialize()              # gives .tensor_frame, .col_stats\n",
    "pod_ds.materialize()\n",
    "\n",
    "# Split ------------------------------------------------------\n",
    "train_eta = eta_ds[:0.8]    # same slice trick as in quick‑tour :contentReference[oaicite:3]{index=3}\n",
    "val_eta   = eta_ds[0.8:]\n",
    "train_pod = pod_ds[:0.8]\n",
    "val_pod   = pod_ds[0.8:]\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3.  Mini‑batch loaders\n",
    "# -----------------------------------------------------------\n",
    "BATCH = 256\n",
    "train_eta_loader = DataLoader(train_eta, batch_size=BATCH, shuffle=True)\n",
    "val_eta_loader   = DataLoader(val_eta,   batch_size=BATCH)\n",
    "\n",
    "train_pod_loader = DataLoader(train_pod, batch_size=BATCH, shuffle=True)\n",
    "val_pod_loader   = DataLoader(val_pod,   batch_size=BATCH)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4.  Common stype‑wise encoders\n",
    "# -----------------------------------------------------------\n",
    "stype_enc = {\n",
    "    tf.stype.categorical: EmbeddingEncoder(),\n",
    "    tf.stype.numerical:   LinearEncoder(),\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5‑A.  ETA regressor  (FT‑Transformer, 1 output)\n",
    "# -----------------------------------------------------------\n",
    "eta_model = FTTransformer(\n",
    "    channels=32,\n",
    "    out_channels=1,\n",
    "    num_layers=3,\n",
    "    col_stats=train_eta.col_stats,\n",
    "    col_names_dict=train_eta.tensor_frame.col_names_dict,\n",
    "    stype_encoder_dict=stype_enc,\n",
    ")\n",
    "opt_eta = torch.optim.AdamW(eta_model.parameters(), lr=1e-3)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5‑B.  POD classifier (same backbone, sigmoid output)\n",
    "# -----------------------------------------------------------\n",
    "pod_model = FTTransformer(\n",
    "    channels=32,\n",
    "    out_channels=1,\n",
    "    num_layers=3,\n",
    "    col_stats=train_pod.col_stats,\n",
    "    col_names_dict=train_pod.tensor_frame.col_names_dict,\n",
    "    stype_encoder_dict=stype_enc,\n",
    ")\n",
    "opt_pod = torch.optim.AdamW(pod_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a50bfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFrame(\n",
      "  num_cols=26,\n",
      "  num_rows=80,\n",
      "  categorical (6): ['Rush_hour', 'is_successful_delivery', 'is_successful_delivery_at_first_time', 'last_delivery_datetime_is_non_working_day', 'parcel_category_id', 'received_datetime_is_non_working_day'],\n",
      "  numerical (20): ['customer_id', 'delivery_post_office_address_latitude', 'delivery_post_office_address_longtitude', 'delivery_post_office_id', 'distance_delivery_post_office_recipient_address', 'distance_received_post_office_delivery_post_office', 'distance_received_post_office_recipient_address', 'last_delivery_datetime_day', 'last_delivery_datetime_hour', 'last_delivery_datetime_month', 'parcel_id', 'received_datetime_day', 'received_datetime_hour', 'received_datetime_month', 'received_post_office_address_latitude', 'received_post_office_address_longtitude', 'received_post_office_id', 'recipient_address_latitude', 'recipient_address_longtitude', 'total_hours_from_receiving_to_last_failed_delivery'],\n",
      "  has_target=True,\n",
      "  device='cpu',\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for tf_batch in train_eta_loader:\n",
    "    print(tf_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd09d216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<stype.categorical: 'categorical'>: tensor([[0, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 2, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 2, 0],\n",
      "        [0, 0, 1, 0, 1, 1],\n",
      "        [1, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 1, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 2, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 1],\n",
      "        [0, 1, 1, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 1, 0, 1, 1],\n",
      "        [1, 0, 1, 0, 2, 0],\n",
      "        [1, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 2, 0]]), <stype.numerical: 'numerical'>: tensor([[1.6280e+03, 1.0694e+01, 1.0665e+02,  ..., 1.0697e+01, 1.0662e+02,\n",
      "         1.9140e+02],\n",
      "        [2.8880e+03, 1.0788e+01, 1.0669e+02,  ..., 1.0781e+01, 1.0670e+02,\n",
      "         0.0000e+00],\n",
      "        [8.7190e+03, 1.0637e+01, 1.0671e+02,  ..., 1.0686e+01, 1.0670e+02,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [9.0780e+03, 1.0766e+01, 1.0660e+02,  ..., 1.0766e+01, 1.0662e+02,\n",
      "         0.0000e+00],\n",
      "        [7.2630e+03, 1.0781e+01, 1.0670e+02,  ..., 1.0785e+01, 1.0669e+02,\n",
      "         0.0000e+00],\n",
      "        [1.0702e+04, 1.0779e+01, 1.0653e+02,  ..., 1.0664e+01, 1.0657e+02,\n",
      "         0.0000e+00]])}\n",
      "{<stype.categorical: 'categorical'>: tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [1, 1, 0, 2, 0],\n",
      "        [0, 0, 0, 2, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 1, 1],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 2, 0],\n",
      "        [1, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 2, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 2, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]), <stype.numerical: 'numerical'>: tensor([[1.7300e+02, 1.0882e+01, 1.0673e+02,  ..., 1.0673e+02, 0.0000e+00,\n",
      "         1.8300e+01],\n",
      "        [3.4520e+03, 1.0776e+01, 1.0665e+02,  ..., 1.0666e+02, 0.0000e+00,\n",
      "         4.0583e+01],\n",
      "        [1.1807e+04, 1.0829e+01, 1.0658e+02,  ..., 1.0657e+02, 0.0000e+00,\n",
      "         2.0633e+01],\n",
      "        ...,\n",
      "        [2.4260e+03, 1.0694e+01, 1.0665e+02,  ..., 1.0657e+02, 0.0000e+00,\n",
      "         2.3983e+01],\n",
      "        [7.4520e+03, 1.0850e+01, 1.0679e+02,  ..., 1.0673e+02, 0.0000e+00,\n",
      "         1.6233e+01],\n",
      "        [1.1739e+04, 1.0796e+01, 1.0668e+02,  ..., 1.0669e+02, 0.0000e+00,\n",
      "         3.1450e+01]])}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (21) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m31\u001b[39m):\n\u001b[32m     18\u001b[39m     eta_loss = train_epoch(eta_model, train_eta_loader, opt_eta, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     pod_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpod_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_pod_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_pod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | ETA MAE-ish \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meta_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | POD BCE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpod_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, is_regression)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tf_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tf_batch.feat_dict)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     target = tf_batch.y.float()\n\u001b[32m     11\u001b[39m     loss = F.smooth_l1_loss(pred.squeeze(), target) \u001b[38;5;28;01mif\u001b[39;00m is_regression \\\n\u001b[32m     12\u001b[39m            \u001b[38;5;28;01melse\u001b[39;00m F.binary_cross_entropy_with_logits(pred.squeeze(), target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/models/ft_transformer.py:105\u001b[39m, in \u001b[36mFTTransformer.forward\u001b[39m\u001b[34m(self, tf)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tf: TensorFrame) -> Tensor:\n\u001b[32m     96\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Transforming :class:`TensorFrame` object into output prediction.\u001b[39;00m\n\u001b[32m     97\u001b[39m \n\u001b[32m     98\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m        torch.Tensor: Output of shape [batch_size, out_channels].\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     x, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     x, x_cls = \u001b[38;5;28mself\u001b[39m.backbone(x)\n\u001b[32m    107\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.decoder(x_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/encoder/stypewise_encoder.py:84\u001b[39m, in \u001b[36mStypeWiseFeatureEncoder.forward\u001b[39m\u001b[34m(self, tf)\u001b[39m\n\u001b[32m     82\u001b[39m feat = tf.feat_dict[stype]\n\u001b[32m     83\u001b[39m col_names = \u001b[38;5;28mself\u001b[39m.col_names_dict[stype]\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m xs.append(x)\n\u001b[32m     86\u001b[39m all_col_names.extend(col_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/base.py:83\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> Any:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.validate()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/encoder/stype_encoder.py:169\u001b[39m, in \u001b[36mStypeEncoder.forward\u001b[39m\u001b[34m(self, feat, col_names)\u001b[39m\n\u001b[32m    167\u001b[39m feat = \u001b[38;5;28mself\u001b[39m.na_forward(feat)\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# Main encoding into column embeddings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Handle NaN in case na_strategy is None\u001b[39;00m\n\u001b[32m    171\u001b[39m x = torch.nan_to_num(x, nan=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/encoder/stype_encoder.py:427\u001b[39m, in \u001b[36mLinearEncoder.encode_forward\u001b[39m\u001b[34m(self, feat, col_names)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_forward\u001b[39m(\n\u001b[32m    422\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    423\u001b[39m     feat: Tensor,\n\u001b[32m    424\u001b[39m     col_names: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    425\u001b[39m ) -> Tensor:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# feat: [batch_size, num_cols]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     feat = (\u001b[43mfeat\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m) / \u001b[38;5;28mself\u001b[39m.std\n\u001b[32m    428\u001b[39m     \u001b[38;5;66;03m# [batch_size, num_cols], [channels, num_cols]\u001b[39;00m\n\u001b[32m    429\u001b[39m     \u001b[38;5;66;03m# -> [batch_size, num_cols, channels]\u001b[39;00m\n\u001b[32m    430\u001b[39m     x_lin = torch.einsum(\u001b[33m\"\u001b[39m\u001b[33mij,jk->ijk\u001b[39m\u001b[33m\"\u001b[39m, feat, \u001b[38;5;28mself\u001b[39m.weight)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (21) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 6.  Plain PyTorch training loops (no Lightning/Rich headaches)\n",
    "# -----------------------------------------------------------\n",
    "def train_epoch(model, loader, optimizer, is_regression: bool):\n",
    "    model.train()\n",
    "    total = 0; loss_sum = 0\n",
    "    for tf_batch in loader:\n",
    "        print(tf_batch.feat_dict)\n",
    "        pred = model(tf_batch)\n",
    "        target = tf_batch.y.float()\n",
    "        loss = F.smooth_l1_loss(pred.squeeze(), target) if is_regression \\\n",
    "               else F.binary_cross_entropy_with_logits(pred.squeeze(), target)\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        loss_sum += loss.item() * len(target); total += len(target)\n",
    "    return loss_sum / total\n",
    "\n",
    "for epoch in range(1, 31):\n",
    "    eta_loss = train_epoch(eta_model, train_eta_loader, opt_eta, True)\n",
    "    pod_loss = train_epoch(pod_model, train_pod_loader, opt_pod, False)\n",
    "    print(f\"Epoch {epoch:02d} | ETA MAE-ish {eta_loss:.3f} | POD BCE {pod_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec3249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4125e9cc7947483e87834d0bec739869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (21) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m31\u001b[39m):\n\u001b[32m    114\u001b[39m     eta_loss = train_epoch(eta_model, train_eta_loader, opt_eta, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     pod_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpod_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_pod_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_pod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | ETA MAE-ish \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meta_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | POD BCE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpod_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------------\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# 7.  Validation & inference\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------------\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, is_regression)\u001b[39m\n\u001b[32m    103\u001b[39m total = \u001b[32m0\u001b[39m; loss_sum = \u001b[32m0\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tf_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     target = tf_batch.y.float()\n\u001b[32m    107\u001b[39m     loss = F.smooth_l1_loss(pred.squeeze(), target) \u001b[38;5;28;01mif\u001b[39;00m is_regression \\\n\u001b[32m    108\u001b[39m            \u001b[38;5;28;01melse\u001b[39;00m F.binary_cross_entropy_with_logits(pred.squeeze(), target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/models/ft_transformer.py:105\u001b[39m, in \u001b[36mFTTransformer.forward\u001b[39m\u001b[34m(self, tf)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tf: TensorFrame) -> Tensor:\n\u001b[32m     96\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Transforming :class:`TensorFrame` object into output prediction.\u001b[39;00m\n\u001b[32m     97\u001b[39m \n\u001b[32m     98\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m        torch.Tensor: Output of shape [batch_size, out_channels].\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     x, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     x, x_cls = \u001b[38;5;28mself\u001b[39m.backbone(x)\n\u001b[32m    107\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.decoder(x_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/encoder/stypewise_encoder.py:84\u001b[39m, in \u001b[36mStypeWiseFeatureEncoder.forward\u001b[39m\u001b[34m(self, tf)\u001b[39m\n\u001b[32m     82\u001b[39m feat = tf.feat_dict[stype]\n\u001b[32m     83\u001b[39m col_names = \u001b[38;5;28mself\u001b[39m.col_names_dict[stype]\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m xs.append(x)\n\u001b[32m     86\u001b[39m all_col_names.extend(col_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/base.py:83\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> Any:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.validate()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/encoder/stype_encoder.py:169\u001b[39m, in \u001b[36mStypeEncoder.forward\u001b[39m\u001b[34m(self, feat, col_names)\u001b[39m\n\u001b[32m    167\u001b[39m feat = \u001b[38;5;28mself\u001b[39m.na_forward(feat)\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# Main encoding into column embeddings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Handle NaN in case na_strategy is None\u001b[39;00m\n\u001b[32m    171\u001b[39m x = torch.nan_to_num(x, nan=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch_frame/nn/encoder/stype_encoder.py:427\u001b[39m, in \u001b[36mLinearEncoder.encode_forward\u001b[39m\u001b[34m(self, feat, col_names)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_forward\u001b[39m(\n\u001b[32m    422\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    423\u001b[39m     feat: Tensor,\n\u001b[32m    424\u001b[39m     col_names: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    425\u001b[39m ) -> Tensor:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# feat: [batch_size, num_cols]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     feat = (\u001b[43mfeat\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m) / \u001b[38;5;28mself\u001b[39m.std\n\u001b[32m    428\u001b[39m     \u001b[38;5;66;03m# [batch_size, num_cols], [channels, num_cols]\u001b[39;00m\n\u001b[32m    429\u001b[39m     \u001b[38;5;66;03m# -> [batch_size, num_cols, channels]\u001b[39;00m\n\u001b[32m    430\u001b[39m     x_lin = torch.einsum(\u001b[33m\"\u001b[39m\u001b[33mij,jk->ijk\u001b[39m\u001b[33m\"\u001b[39m, feat, \u001b[38;5;28mself\u001b[39m.weight)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (21) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 7.  Validation & inference\n",
    "# -----------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, is_regression):\n",
    "    model.eval()\n",
    "    outs, ys = [], []\n",
    "    for tf_batch in loader:\n",
    "        outs.append(model(tf_batch).cpu())\n",
    "        ys.append(tf_batch.y.float().cpu())\n",
    "    pred = torch.cat(outs).squeeze()\n",
    "    y    = torch.cat(ys).squeeze()\n",
    "    if is_regression:\n",
    "        return torch.mean(torch.abs(pred - y)).item()      # MAE\n",
    "    else:\n",
    "        prob = torch.sigmoid(pred)\n",
    "        acc  = ((prob > 0.5) == y.bool()).float().mean()\n",
    "        return acc.item()\n",
    "\n",
    "print(\"ETA MAE (val):\", evaluate(eta_model, val_eta_loader, True))\n",
    "print(\"POD ACC (val):\", evaluate(pod_model, val_pod_loader, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653329d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cbce4ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84c48af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cfa3a8fcae4b1196b671a897b95c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/parcel_tracking_output_data.parquet\"         # or .xlsx after conversion\n",
    "df = duckdb.sql(f\"\"\"\n",
    "    SELECT * FROM '{file_path}'\n",
    "    USING SAMPLE reservoir(100 ROWS)\n",
    "    REPEATABLE (100)\n",
    "\"\"\").df()\n",
    "\n",
    "df = df.dropna(subset=[\n",
    "    \"total_hours_from_receiving_to_last_success_delivery\",\n",
    "    \"is_successful_delivery\",\n",
    "])\n",
    "\n",
    "# Cast targets\n",
    "df[\"is_successful_delivery\"] = df[\"is_successful_delivery\"].astype(int)\n",
    "df[\"total_hours_from_receiving_to_last_success_delivery\"] = (\n",
    "    df[\"total_hours_from_receiving_to_last_success_delivery\"].astype(float)\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "target_reg = [\"total_hours_from_receiving_to_last_success_delivery\"]\n",
    "target_cls = [\"is_successful_delivery\"]\n",
    "categorical_cols = [c for c in df.select_dtypes(\"object\").columns]\n",
    "continuous_cols  = [c for c in df.columns if c not in categorical_cols + target_reg + target_cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04902d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">705</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:03\u001b[0m,\u001b[1;36m705\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">754</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:03\u001b[0m,\u001b[1;36m754\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">758</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:03\u001b[0m,\u001b[1;36m758\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.56384729 -1.44989302  0.56384729  0.56384729  0.56384729  0.56384729\n",
      " -1.44989302 -2.45676318 -1.44989302  0.56384729 -1.44989302  0.56384729\n",
      " -1.44989302  0.56384729  0.56384729 -2.45676318 -2.45676318  0.56384729\n",
      " -1.44989302  0.56384729  0.56384729  0.56384729 -1.44989302  0.56384729\n",
      " -2.45676318  0.56384729  0.56384729 -1.44989302 -1.44989302  0.56384729\n",
      "  0.56384729  0.56384729  0.56384729 -1.44989302  0.56384729  0.56384729\n",
      "  0.56384729  0.56384729  0.56384729  0.56384729 -1.44989302 -1.44989302\n",
      "  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729\n",
      "  0.56384729  0.56384729  0.56384729 -2.45676318  0.56384729  0.56384729\n",
      "  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729\n",
      "  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729 -1.44989302\n",
      "  0.56384729  0.56384729  0.56384729 -1.44989302 -1.44989302  0.56384729\n",
      " -1.44989302  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729\n",
      "  0.56384729  0.56384729  0.56384729 -1.44989302  0.56384729  0.56384729\n",
      "  0.56384729 -1.44989302  0.56384729  0.56384729  0.56384729 -1.44989302\n",
      "  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729  0.56384729\n",
      "  0.56384729  0.56384729  0.56384729 -2.45676318]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.73607789e-02 -5.51173050e-01 -5.70445204e-01  2.18393107e-01\n",
      "  1.76412547e+00 -3.01163050e-01 -7.31222490e-01  1.74643733e+00\n",
      "  1.04366371e+00 -9.23152026e-01 -8.60055521e-01 -1.92394179e-01\n",
      " -5.50645046e-01  1.76412547e+00  1.76412547e+00  1.14873655e+00\n",
      " -7.30958488e-01  9.48886952e-01 -1.31651517e+00 -1.34740342e+00\n",
      "  3.73098345e-01 -8.73519629e-01 -4.41612173e-01  6.10436244e-01\n",
      "  1.47240314e+00 -1.31757118e+00  5.02459380e-01 -1.31651517e+00\n",
      " -6.83174106e-01 -5.85493324e-01  6.06212210e-01  6.14396276e-01\n",
      "  6.14396276e-01 -1.32205922e+00 -1.31673693e-01 -8.60583525e-01\n",
      " -1.30727510e+00  5.91364731e-04 -1.32364323e+00 -8.51343451e-01\n",
      " -5.90509365e-01  5.02987384e-01 -1.32153121e+00 -5.70445204e-01\n",
      " -1.34740342e+00  6.14396276e-01  1.00384163e-01  5.64499876e-01\n",
      " -1.32364323e+00  1.76412547e+00  3.23201946e-01  1.74643733e+00\n",
      "  8.83942432e-01  1.29994640e-02 -8.65863568e-01  1.76412547e+00\n",
      " -3.15155161e-01  1.74617333e+00  3.23201946e-01  1.66648693e-01\n",
      "  1.74617333e+00  1.76412547e+00 -7.12478340e-01  6.05684206e-01\n",
      "  1.51939552e+00 -3.46835415e-01 -1.32126721e+00  1.42541076e+00\n",
      "  1.74617333e+00 -5.81269291e-01 -3.01163050e-01 -8.59263515e-01\n",
      "  4.72627141e-01 -1.34001136e+00  6.14396276e-01  1.76412547e+00\n",
      " -1.22121041e+00  6.28388388e-01 -4.32636101e-01  4.17450700e-01\n",
      " -3.15155161e-01  4.57315019e-01  1.97008936e-01 -8.48175426e-01\n",
      "  1.74617333e+00  4.57315019e-01 -7.78478868e-01 -1.31862719e+00\n",
      " -1.19771422e+00 -1.88698150e-01 -7.31750495e-01 -1.31673693e-01\n",
      " -1.31255514e+00 -3.15155161e-01  9.51790975e-01 -8.09631118e-01\n",
      "  6.14396276e-01 -8.17287179e-01 -3.15155161e-01 -1.19586621e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.18891229  0.76506338 -0.35209234 -1.34372494 -0.7537663  -0.90439404\n",
      " -1.26841107 -0.33954002  1.90732372  1.01610961 -0.70355706 -0.90439404\n",
      " -0.90439404 -0.2014646  -0.15125535  0.76506338 -1.26841107  0.76506338\n",
      "  0.36338942 -0.87928941  0.43870328 -1.26841107 -1.05502177  1.09142348\n",
      "  0.76506338 -0.54037701  0.70230182  0.36338942 -0.99226022 -0.82908017\n",
      "  1.05376654 -1.28096338 -1.28096338  0.76506338 -0.21401691 -1.34372494\n",
      " -1.28096338 -0.15125535  0.76506338  1.32991739 -0.82908017  0.76506338\n",
      "  0.76506338  1.84456216  0.76506338 -1.28096338  0.28807555  1.65627749\n",
      "  0.76506338  1.70648674  0.57677871 -0.99226022  1.63117287 -0.18891229\n",
      "  0.76506338  1.63117287  0.02447701  0.42615097  0.57677871  0.30062786\n",
      "  0.57677871 -0.2014646  -1.13033564  1.02866192 -1.34372494 -0.65334781\n",
      "  0.76506338 -1.34372494 -0.7537663  -0.90439404 -0.54037701 -1.09267871\n",
      "  1.17928966 -1.28096338 -1.28096338  1.49309744  1.49309744 -0.90439404\n",
      " -0.90439404  0.76506338  1.32991739  0.73995876  0.37594173 -1.34372494\n",
      " -1.06757409  0.73995876 -1.28096338 -0.90439404  1.02866192 -0.54037701\n",
      " -1.34372494 -0.21401691  1.32991739  1.09142348  1.65627749 -1.28096338\n",
      " -1.28096338  0.81527263  0.76506338  0.76506338]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.20111759  1.31206964 -0.42617916  0.95455748 -0.57411522  0.52307728\n",
      "  0.30117318 -0.99326742  1.63259779  0.5723893  -1.37543559 -0.99326742\n",
      " -1.30146756  1.63259779  1.18878959  1.60794178 -1.37543559  1.31206964\n",
      " -1.07956346 -1.37543559  0.5723893  -0.91929938  0.74498138  0.62170133\n",
      "  0.42445323 -1.11654747 -0.57411522  0.64635734 -0.80834733  0.64635734\n",
      "  0.9915415  -0.57411522 -1.11654747 -1.37543559  1.69423782  1.60794178\n",
      " -0.82067534 -0.26591508 -0.66041126 -0.05633899 -1.37543559  1.60794178\n",
      "  0.5723893   1.0038695   1.18878959 -0.80834733  1.01619751 -1.30146756\n",
      " -1.11654747  0.5723893  -0.57411522 -1.37543559 -1.30146756 -0.25358708\n",
      " -0.03168297  0.9915415   0.1285811  -0.66041126 -0.57411522  0.30117318\n",
      "  0.95455748  0.54773329  0.5723893   1.07783754 -0.26591508 -1.30146756\n",
      "  0.64635734 -1.21517152 -0.57411522 -0.99326742 -0.57411522 -1.1781875\n",
      " -1.21517152 -1.30146756 -0.47549118  0.5723893  -0.19194705 -1.07956346\n",
      "  0.62170133  1.49698973  1.26275762 -0.77136331  0.42445323  0.30117318\n",
      "  0.95455748 -1.07956346  0.54773329 -0.57411522  1.60794178 -0.91929938\n",
      " -0.91929938  1.07783754  1.55862976  0.9915415   1.55862976 -0.66041126\n",
      " -0.66041126 -1.1781875  -1.26448354  1.20111759]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.52924649  0.36274197  0.06541249  0.36274197 -1.12390546  0.95740095\n",
      " -0.231917    1.25473043 -2.01589392 -1.12390546  0.95740095  1.25473043\n",
      " -0.231917   -0.82657597  0.06541249  1.25473043 -1.42123494  0.95740095\n",
      " -1.71856443 -0.82657597  0.06541249  0.95740095  1.8493894   0.66007146\n",
      "  2.44404838  0.06541249 -0.52924649 -0.231917   -1.42123494 -1.71856443\n",
      " -1.42123494  0.95740095  0.66007146  0.06541249 -2.01589392  1.55205992\n",
      "  0.06541249  0.95740095  1.55205992 -1.12390546 -0.231917    1.8493894\n",
      "  1.8493894   0.66007146  0.06541249 -1.12390546 -0.231917   -0.231917\n",
      "  0.95740095  0.36274197  0.66007146 -1.42123494 -1.12390546  0.36274197\n",
      "  0.95740095  0.66007146  0.36274197 -2.3132234   0.36274197 -1.12390546\n",
      " -2.3132234  -0.52924649 -1.71856443  0.06541249  0.36274197 -0.231917\n",
      "  0.06541249  0.66007146  0.36274197  0.95740095  0.06541249 -0.52924649\n",
      " -0.52924649  0.95740095  0.66007146  0.95740095  0.06541249  0.06541249\n",
      " -0.231917   -1.12390546  0.95740095  0.06541249 -0.231917    0.95740095\n",
      "  0.06541249 -1.12390546  0.36274197  0.06541249  0.36274197 -0.52924649\n",
      "  0.95740095 -1.12390546  0.66007146  0.36274197 -1.71856443 -0.231917\n",
      "  0.66007146  0.36274197  0.36274197 -1.42123494]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.27842944  0.27842944  1.57345011 -0.36908089 -1.66410156  0.27842944\n",
      "  1.57345011 -1.66410156  1.57345011 -0.36908089 -1.01659122  0.27842944\n",
      "  0.92593978  0.27842944  0.92593978 -0.36908089 -0.36908089  0.27842944\n",
      "  0.27842944 -0.36908089  1.57345011  0.27842944  1.57345011  0.27842944\n",
      " -0.36908089  0.92593978  0.27842944  0.27842944 -0.36908089  1.57345011\n",
      "  0.92593978 -0.36908089 -1.01659122  0.27842944  0.92593978  0.92593978\n",
      " -1.01659122  1.57345011  0.92593978 -2.31161189  0.27842944  0.27842944\n",
      " -1.01659122  0.92593978 -1.66410156  0.27842944  0.27842944  1.57345011\n",
      " -0.36908089  1.57345011 -1.66410156 -0.36908089 -0.36908089 -1.01659122\n",
      " -0.36908089  0.92593978  0.27842944  0.27842944  1.57345011 -0.36908089\n",
      "  0.92593978 -1.01659122 -0.36908089 -1.01659122  0.92593978 -1.66410156\n",
      "  0.27842944 -1.66410156 -0.36908089  0.27842944 -1.66410156  0.27842944\n",
      "  0.27842944  0.27842944 -1.66410156 -1.66410156 -0.36908089 -1.66410156\n",
      "  1.57345011 -1.01659122  0.92593978  0.92593978 -1.66410156  0.27842944\n",
      "  0.92593978  1.57345011 -1.66410156 -1.66410156  0.92593978  0.27842944\n",
      "  0.27842944  0.92593978 -0.36908089 -1.01659122 -0.36908089 -1.01659122\n",
      " -0.36908089  0.27842944  0.27842944 -0.36908089]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.15985756 -0.65297747 -1.4658125  -0.92392248  0.43080257  0.97269258\n",
      " -1.4658125   0.97269258  0.15985756 -0.38203246  0.97269258 -0.92392248\n",
      " -1.4658125   1.24363759  0.97269258  0.97269258  1.5145826  -0.65297747\n",
      " -0.92392248 -0.92392248  0.70174757 -0.65297747 -0.65297747 -0.38203246\n",
      "  0.70174757 -1.19486749  0.43080257 -1.4658125  -0.65297747 -0.38203246\n",
      " -1.4658125  -1.4658125  -0.92392248 -1.19486749 -1.4658125   0.97269258\n",
      "  1.24363759  0.97269258  1.24363759  0.15985756 -0.38203246 -0.92392248\n",
      " -1.4658125  -0.65297747  0.97269258  1.24363759  0.43080257  1.24363759\n",
      "  1.24363759  0.97269258  0.70174757 -0.38203246  1.5145826   0.15985756\n",
      "  1.5145826   1.24363759  0.97269258  0.97269258  0.97269258 -0.65297747\n",
      "  1.5145826   1.24363759  0.97269258 -1.4658125   1.24363759 -0.92392248\n",
      " -0.92392248  1.24363759  0.15985756 -1.4658125   0.15985756 -0.92392248\n",
      " -0.92392248 -0.38203246  0.15985756  1.5145826  -0.92392248  1.5145826\n",
      " -0.92392248 -0.92392248  0.97269258 -0.65297747  1.24363759 -0.92392248\n",
      "  0.97269258 -0.65297747 -0.92392248 -0.65297747  0.43080257  0.15985756\n",
      " -1.19486749 -1.4658125   0.43080257  0.70174757 -1.4658125   0.15985756\n",
      " -0.65297747 -1.19486749  1.24363759  0.70174757]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.38655567 -0.38655567  2.5869495  -0.38655567 -0.38655567 -0.38655567\n",
      "  2.5869495  -0.38655567  2.5869495  -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567  2.5869495  -0.38655567  2.5869495  -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567  2.5869495\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567  2.5869495  -0.38655567  2.5869495  -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567  2.5869495\n",
      " -0.38655567  2.5869495  -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567  2.5869495  -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      "  2.5869495  -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567  2.5869495  -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567 -0.38655567]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.70181003  1.42488702 -0.70181003 -0.70181003  1.42488702  1.42488702\n",
      " -0.70181003  1.42488702  1.42488702 -0.70181003 -0.70181003  1.42488702\n",
      " -0.70181003  1.42488702 -0.70181003  1.42488702 -0.70181003 -0.70181003\n",
      " -0.70181003 -0.70181003  1.42488702  1.42488702 -0.70181003 -0.70181003\n",
      " -0.70181003 -0.70181003 -0.70181003 -0.70181003 -0.70181003 -0.70181003\n",
      " -0.70181003 -0.70181003  1.42488702 -0.70181003 -0.70181003 -0.70181003\n",
      " -0.70181003 -0.70181003 -0.70181003 -0.70181003 -0.70181003  1.42488702\n",
      " -0.70181003  1.42488702  1.42488702 -0.70181003 -0.70181003 -0.70181003\n",
      " -0.70181003  1.42488702  1.42488702 -0.70181003  1.42488702 -0.70181003\n",
      "  1.42488702 -0.70181003  1.42488702 -0.70181003 -0.70181003 -0.70181003\n",
      " -0.70181003 -0.70181003  1.42488702  1.42488702  1.42488702 -0.70181003\n",
      " -0.70181003 -0.70181003 -0.70181003 -0.70181003  1.42488702 -0.70181003\n",
      " -0.70181003 -0.70181003  1.42488702 -0.70181003 -0.70181003  1.42488702\n",
      " -0.70181003 -0.70181003 -0.70181003 -0.70181003 -0.70181003 -0.70181003\n",
      "  1.42488702  1.42488702  1.42488702 -0.70181003  1.42488702  1.42488702\n",
      " -0.70181003  1.42488702 -0.70181003 -0.70181003 -0.70181003  1.42488702\n",
      "  1.42488702 -0.70181003 -0.70181003 -0.70181003]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.57961884 -0.94188062  1.23169005  0.14490471 -0.94188062 -0.94188062\n",
      "  1.59395182 -0.94188062 -0.94188062 -0.57961884  0.86942827 -1.3041424\n",
      "  0.86942827 -0.94188062  0.86942827 -1.3041424  -0.21735707  0.50716649\n",
      " -0.57961884 -0.57961884 -1.3041424   1.9562136   0.50716649  0.14490471\n",
      "  1.59395182 -0.57961884 -0.57961884  1.59395182  0.14490471  0.14490471\n",
      " -0.21735707 -0.57961884 -0.94188062 -0.57961884  0.50716649  0.86942827\n",
      " -0.57961884  0.14490471 -0.57961884 -0.57961884 -0.57961884 -0.94188062\n",
      "  0.86942827 -0.94188062 -0.94188062  0.14490471  0.86942827 -0.21735707\n",
      " -0.21735707 -0.94188062 -0.94188062  1.59395182  2.68073716 -0.21735707\n",
      " -0.94188062  0.86942827 -1.3041424   0.86942827  0.50716649  1.23169005\n",
      "  1.23169005 -0.57961884 -0.94188062 -0.94188062 -1.66640418  0.14490471\n",
      " -0.57961884  1.23169005  0.50716649  1.59395182 -0.94188062 -0.57961884\n",
      " -0.21735707 -0.57961884 -1.3041424   1.59395182  1.59395182 -0.94188062\n",
      " -0.57961884 -0.21735707 -0.21735707  0.14490471 -0.57961884  1.59395182\n",
      "  1.9562136  -0.94188062 -0.94188062  0.86942827  1.9562136   2.31847538\n",
      " -0.21735707 -0.94188062 -0.57961884 -0.57961884  0.14490471  1.9562136\n",
      " -0.94188062 -0.57961884 -0.21735707  0.14490471]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.90293224  1.46726488 -1.35439836  0.33859959 -0.79006571  1.46726488\n",
      " -1.35439836 -0.22573306 -1.35439836  0.33859959 -0.22573306  0.90293224\n",
      " -1.35439836  0.90293224  1.46726488  0.90293224  0.33859959  1.46726488\n",
      "  0.90293224  0.33859959 -0.79006571  0.90293224 -1.35439836  0.90293224\n",
      "  0.33859959 -1.35439836  0.90293224  0.90293224  0.33859959 -1.35439836\n",
      "  1.46726488  0.33859959 -0.22573306  0.90293224 -1.35439836  1.46726488\n",
      " -0.22573306 -1.918731   -1.35439836 -1.35439836  0.90293224  0.90293224\n",
      " -0.22573306 -1.35439836 -0.79006571  0.90293224  0.90293224 -1.918731\n",
      "  0.90293224 -1.35439836 -0.79006571  0.33859959  0.33859959 -0.22573306\n",
      "  0.33859959 -1.35439836  0.90293224  0.90293224 -0.22573306  0.90293224\n",
      "  1.46726488 -0.22573306  0.33859959  0.33859959 -1.918731   -0.79006571\n",
      "  0.90293224 -0.79006571  0.33859959  0.90293224 -0.79006571  0.90293224\n",
      "  0.90293224  0.90293224 -0.79006571 -0.79006571 -1.35439836 -0.79006571\n",
      " -1.918731   -0.22573306 -1.35439836 -1.35439836 -0.79006571  0.90293224\n",
      "  0.90293224 -1.35439836 -0.79006571 -0.79006571  0.33859959  0.90293224\n",
      "  0.90293224  1.46726488  0.33859959 -0.22573306  0.33859959  0.33859959\n",
      "  0.90293224 -1.35439836  0.90293224  0.90293224]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.14584797 -0.66441851 -1.47468499 -0.93450734  0.41593679  0.95611444\n",
      " -1.47468499  0.95611444  0.14584797 -0.39432968  0.95611444 -0.93450734\n",
      " -1.47468499  1.22620327  0.95611444  0.95611444  1.49629209 -0.66441851\n",
      " -0.93450734 -0.93450734  0.68602562 -0.66441851 -0.66441851 -0.39432968\n",
      "  0.68602562 -1.20459616  0.41593679 -1.47468499 -0.66441851 -0.39432968\n",
      " -1.47468499 -1.47468499 -0.93450734 -0.93450734 -1.47468499  0.95611444\n",
      "  1.22620327  0.95611444  1.22620327  0.14584797 -0.39432968 -0.93450734\n",
      " -1.47468499 -0.66441851  0.95611444  1.22620327  0.41593679  1.22620327\n",
      "  1.49629209  0.95611444  0.95611444 -0.39432968  1.49629209  0.14584797\n",
      "  1.49629209  1.49629209  0.95611444  0.95611444  0.95611444 -0.66441851\n",
      "  1.49629209  1.22620327  0.95611444 -1.20459616  1.22620327 -0.93450734\n",
      " -0.93450734  1.22620327  0.14584797 -1.47468499  0.14584797 -0.93450734\n",
      " -0.93450734 -0.39432968  0.14584797  1.49629209 -0.93450734  1.49629209\n",
      " -0.93450734 -0.93450734  0.95611444 -0.66441851  1.22620327 -0.93450734\n",
      "  0.95611444 -0.66441851 -0.93450734 -0.66441851  0.41593679  0.14584797\n",
      " -1.20459616 -1.47468499  0.41593679  0.68602562 -1.47468499  0.14584797\n",
      " -0.66441851 -1.20459616  1.22620327  0.68602562]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.36927447  2.7080128  -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447  2.7080128  -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      "  2.7080128  -0.36927447 -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447  2.7080128  -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      "  2.7080128  -0.36927447 -0.36927447 -0.36927447  2.7080128  -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      "  2.7080128  -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447  2.7080128  -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.93345474  1.28126765  0.64217158 -0.54462806 -0.97943147 -0.27612782\n",
      "  1.71878494 -1.67594349  1.2907739   0.32791282  1.33427428 -1.30106254\n",
      "  1.16883641 -0.63723681 -0.74740844 -1.74784319 -1.72780749 -0.56855873\n",
      "  1.25724832 -1.42714081 -0.92697289 -1.44486672  1.65913027  0.71566782\n",
      " -1.76509175 -1.36642594 -1.36663769  1.25820302  1.28562384 -1.29561464\n",
      "  1.0181032   0.4204886   0.42671827  1.30628636 -0.95208795 -1.23862622\n",
      " -0.88794813  0.48920148 -0.10892087 -1.01804153  1.39318418  1.35664139\n",
      "  0.33086628 -0.51561327  0.04068253 -0.28879379  0.0918274   0.59533235\n",
      "  0.60381467 -0.73614777 -0.79971975 -1.61496412 -0.24295503  0.93669028\n",
      " -0.06639643 -0.59344519  0.92301357  0.04023119  0.35416025  0.49486442\n",
      "  0.31252345 -0.60135894 -1.30495677  0.71699764 -0.10924435  1.25377209\n",
      "  0.70836439  0.59728606 -0.18910251  1.1768978   1.41036753 -1.40231114\n",
      "  1.56596211 -0.46368626  0.44465959 -0.50361845  0.53002353  0.07237345\n",
      " -0.54885603 -0.54596228 -0.06266009  1.64272576 -0.53867094 -1.56606713\n",
      "  0.21009779  1.48429751  0.86028528 -1.41309226 -0.12049843  1.41149476\n",
      "  0.68118828 -0.96075198 -1.04400211 -0.30994684  0.9923932  -0.83017171\n",
      "  0.42867528  1.00478698 -0.042117   -1.78109474]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.73379939 -1.36277029 -1.36277029  0.73379939  0.73379939 -1.36277029\n",
      " -1.36277029  0.73379939  0.73379939 -1.36277029  0.73379939  0.73379939\n",
      " -1.36277029  0.73379939 -1.36277029 -1.36277029  0.73379939 -1.36277029\n",
      "  0.73379939  0.73379939  0.73379939 -1.36277029 -1.36277029  0.73379939\n",
      "  0.73379939 -1.36277029  0.73379939 -1.36277029  0.73379939  0.73379939\n",
      "  0.73379939  0.73379939  0.73379939  0.73379939 -1.36277029  0.73379939\n",
      "  0.73379939 -1.36277029 -1.36277029  0.73379939  0.73379939  0.73379939\n",
      "  0.73379939  0.73379939  0.73379939  0.73379939  0.73379939  0.73379939\n",
      " -1.36277029 -1.36277029  0.73379939  0.73379939 -1.36277029  0.73379939\n",
      "  0.73379939 -1.36277029  0.73379939  0.73379939 -1.36277029 -1.36277029\n",
      "  0.73379939  0.73379939  0.73379939 -1.36277029 -1.36277029  0.73379939\n",
      "  0.73379939  0.73379939  0.73379939  0.73379939  0.73379939 -1.36277029\n",
      "  0.73379939  0.73379939 -1.36277029  0.73379939 -1.36277029  0.73379939\n",
      "  0.73379939  0.73379939 -1.36277029 -1.36277029  0.73379939  0.73379939\n",
      " -1.36277029  0.73379939  0.73379939  0.73379939 -1.36277029 -1.36277029\n",
      "  0.73379939  0.73379939  0.73379939  0.73379939  0.73379939 -1.36277029\n",
      "  0.73379939 -1.36277029  0.73379939 -1.36277029]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.56384729  0.56384729 -1.44989302  0.56384729  0.56384729  0.56384729\n",
      " -1.44989302  0.56384729 -1.44989302  0.56384729 -1.44989302  0.56384729\n",
      "  0.56384729 -1.44989302  0.56384729]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.84817543  0.01299946 -0.30116305  0.61439628 -1.34740342 -0.85134345\n",
      " -0.44161217 -0.31515516 -0.86005552 -0.01736078 -1.31651517  0.60621221\n",
      " -1.34001136 -1.32205922 -0.73175049]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.34372494 -0.18891229 -0.54037701 -1.28096338  0.76506338  1.32991739\n",
      " -1.05502177  1.32991739 -0.70355706 -0.18891229  0.36338942  1.05376654\n",
      " -1.28096338  0.76506338 -1.34372494]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.30117318 -0.25358708 -0.57411522 -0.80834733  1.18878959 -0.05633899\n",
      "  0.74498138  1.26275762 -1.37543559  1.20111759 -1.07956346  0.9915415\n",
      " -1.30146756 -1.37543559 -0.91929938]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.95740095  0.36274197  0.06541249 -1.12390546  0.06541249 -1.12390546\n",
      "  1.8493894   0.95740095  0.95740095 -0.52924649 -1.71856443 -1.42123494\n",
      "  0.95740095  0.06541249  0.95740095]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.27842944 -1.01659122 -1.66410156  0.27842944 -1.66410156 -2.31161189\n",
      "  1.57345011  0.92593978 -1.01659122  0.27842944  0.27842944  0.92593978\n",
      "  0.27842944  0.27842944  0.27842944]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.92392248  0.15985756  0.15985756  1.24363759  0.97269258  0.15985756\n",
      " -0.65297747  0.97269258  0.97269258  0.15985756 -0.92392248 -1.4658125\n",
      " -0.38203246 -1.19486749 -1.19486749]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567  2.5869495\n",
      "  2.5869495  -0.38655567 -0.38655567 -0.38655567 -0.38655567 -0.38655567\n",
      " -0.38655567 -0.38655567 -0.38655567]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.70181003 -0.70181003  1.42488702 -0.70181003  1.42488702 -0.70181003\n",
      " -0.70181003 -0.70181003 -0.70181003 -0.70181003 -0.70181003 -0.70181003\n",
      " -0.70181003 -0.70181003 -0.70181003]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.59395182 -0.21735707 -0.94188062  0.14490471 -0.94188062 -0.57961884\n",
      "  0.50716649 -0.21735707  0.86942827 -0.57961884 -0.57961884 -0.21735707\n",
      " -0.57961884 -0.57961884 -0.21735707]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.90293224 -0.22573306 -0.79006571  0.90293224 -0.79006571 -1.35439836\n",
      " -1.35439836 -1.35439836 -0.22573306  0.90293224  0.90293224  1.46726488\n",
      "  0.90293224  0.90293224  0.90293224]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.93450734  0.14584797  0.14584797  1.22620327  0.95611444  0.14584797\n",
      " -0.66441851  0.95611444  0.95611444  0.14584797 -0.93450734 -1.47468499\n",
      " -0.39432968 -0.93450734 -1.20459616]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447 -0.36927447 -0.36927447]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.56606713  0.93669028  1.41036753 -0.28879379  0.04068253 -1.01804153\n",
      "  1.65913027 -0.06266009  1.33427428  0.93345474  1.25724832  1.0181032\n",
      " -0.46368626  1.30628636  0.68118828]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.73379939  0.73379939  0.73379939  0.73379939  0.73379939  0.73379939\n",
      " -1.36277029 -1.36277029  0.73379939  0.73379939  0.73379939  0.73379939\n",
      "  0.73379939  0.73379939  0.73379939]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">889</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: NODEModel              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:03\u001b[0m,\u001b[1;36m889\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: NODEModel              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/models/node/node_model.py:110: UserWarning: Ignoring head config because NODE has a specific head which subsets the tree outputs\n",
      "  warnings.warn(\"Ignoring head config because NODE has a specific head which subsets the tree outputs\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">933</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.node.node_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span> batch size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:03\u001b[0m,\u001b[1;36m933\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.node.node_model:\u001b[1;36m73\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with \u001b[1;36m2000\u001b[0m batch size\u001b[33m...\u001b[0m.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/models/common/layers/soft_trees.py:138: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:04</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:04\u001b[0m,\u001b[1;36m151\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:04</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">277</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:04\u001b[0m,\u001b[1;36m277\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/nguynking/eta/notebook/saved_models exists and is not empty.\n",
      "\n",
      "  | Name             | Type             | Params\n",
      "------------------------------------------------------\n",
      "0 | _backbone        | NODEBackbone     | 8.4 K \n",
      "1 | _embedding_layer | Embedding1dLayer | 50    \n",
      "2 | _head            | Lambda           | 0     \n",
      "3 | loss             | MSELoss          | 0     \n",
      "------------------------------------------------------\n",
      "8.3 K     Trainable params\n",
      "196       Non-trainable params\n",
      "8.5 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/nguynking/eta/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">952</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:18\u001b[0m,\u001b[1;36m952\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:17:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">954</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:17:18\u001b[0m,\u001b[1;36m954\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.dictconfig.DictConfig])` or the `torch.serialization.safe_globals([omegaconf.dictconfig.DictConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     28\u001b[39m optim_reg = OptimizerConfig(\n\u001b[32m     29\u001b[39m     optimizer        = \u001b[33m\"\u001b[39m\u001b[33mAdamW\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m     optimizer_params = {\u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1e-5\u001b[39m},\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m eta_model = TabularModel(\n\u001b[32m     34\u001b[39m     data_config      = data_reg,\n\u001b[32m     35\u001b[39m     model_config     = model_reg,\n\u001b[32m     36\u001b[39m     trainer_config   = trainer_reg,\n\u001b[32m     37\u001b[39m     optimizer_config = optim_reg,\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43meta_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrac\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_model.py:779\u001b[39m, in \u001b[36mTabularModel.fit\u001b[39m\u001b[34m(self, train, validation, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule, cache_data, handle_oom)\u001b[39m\n\u001b[32m    765\u001b[39m         warnings.warn(\n\u001b[32m    766\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtrain data and datamodule is provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    767\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Ignoring the train data and using the datamodule.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    768\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Set either one of them to None to avoid this warning.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    769\u001b[39m         )\n\u001b[32m    770\u001b[39m model = \u001b[38;5;28mself\u001b[39m.prepare_model(\n\u001b[32m    771\u001b[39m     datamodule,\n\u001b[32m    772\u001b[39m     loss,\n\u001b[32m   (...)\u001b[39m\u001b[32m    776\u001b[39m     optimizer_params \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[32m    777\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_oom\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_model.py:665\u001b[39m, in \u001b[36mTabularModel.train\u001b[39m\u001b[34m(self, model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\u001b[39m\n\u001b[32m    663\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mTraining the model completed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.load_best:\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/tabular_model.py:1494\u001b[39m, in \u001b[36mTabularModel.load_best_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1492\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1493\u001b[39m         logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel Checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m     ckpt = \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1495\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.load_state_dict(ckpt[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1496\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:84\u001b[39m, in \u001b[36mpl_load\u001b[39m\u001b[34m(path_or_url, map_location)\u001b[39m\n\u001b[32m     82\u001b[39m fs = get_filesystem(path_or_url)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fs.open(path_or_url, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eta/.venv/lib/python3.12/site-packages/torch/serialization.py:1524\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1516\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m                     opened_zipfile,\n\u001b[32m   1518\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1521\u001b[39m                     **pickle_load_args,\n\u001b[32m   1522\u001b[39m                 )\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.dictconfig.DictConfig])` or the `torch.serialization.safe_globals([omegaconf.dictconfig.DictConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import NodeConfig\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "\n",
    "data_reg = DataConfig(\n",
    "    target           = target_reg,\n",
    "    continuous_cols  = continuous_cols,\n",
    "    categorical_cols = categorical_cols,\n",
    ")\n",
    "\n",
    "model_reg = NodeConfig(\n",
    "    num_layers   = 4,\n",
    "    num_trees    = 8,\n",
    "    depth        = 3,\n",
    "    task         = \"regression\",\n",
    "    learning_rate= 1e-3,\n",
    "    metrics      = [\"mean_absolute_error\"],\n",
    ")\n",
    "\n",
    "trainer_reg = TrainerConfig(\n",
    "    max_epochs        = 50,\n",
    "    batch_size        = 10,\n",
    "    auto_lr_find      = False,          # keep LR‑Finder off (previous fix)\n",
    "    accelerator       = \"cpu\",\n",
    "    trainer_kwargs={\"enable_progress_bar\": False}\n",
    ")\n",
    "\n",
    "optim_reg = OptimizerConfig(\n",
    "    optimizer        = \"AdamW\",\n",
    "    optimizer_params = {\"weight_decay\": 1e-5},\n",
    ")\n",
    "\n",
    "eta_model = TabularModel(\n",
    "    data_config      = data_reg,\n",
    "    model_config     = model_reg,\n",
    "    trainer_config   = trainer_reg,\n",
    "    optimizer_config = optim_reg,\n",
    ")\n",
    "\n",
    "eta_model.fit(train=df, validation=df.sample(frac=0.15, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.load(\"saved_models/regression-5_epoch=49-valid_loss=678.95.ckpt\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac4072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e87a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models import NodeConfig                # fast MLP trunk\n",
    "from pytorch_tabular.models.common.heads import (\n",
    "    RegressionHeadConfig,\n",
    "    ClassificationHeadConfig,\n",
    "    MultiTaskHeadConfig,\n",
    ")\n",
    "\n",
    "# 1) DataConfig  (tells PT‑Tabular what columns mean what)\n",
    "data_config = DataConfig(\n",
    "    target=target_cols,                    # two targets\n",
    "    continuous_cols=continuous_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    continuous_feature_transform=\"standardize\",\n",
    "    categorical_encoder=\"embedding\",       # learn embeddings for high‑card cat\n",
    ")\n",
    "\n",
    "# 2) Shared trunk  (Node = residual MLP, similar to FT‑Transformer without attention)\n",
    "model_config = NodeConfig(\n",
    "    task=\"multitask\",                      # important!\n",
    "    num_layers=4,\n",
    "    num_trees=8,                           # Node’s internal structure\n",
    "    depth=2,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "# 3) Two heads\n",
    "reg_head = RegressionHeadConfig(\n",
    "    head=\"eta\",\n",
    "    output_dim=1,\n",
    "    loss=\"SmoothL1Loss\",\n",
    "    metric_list=[\"mae\", \"rmse\"],\n",
    ")\n",
    "\n",
    "cls_head = ClassificationHeadConfig(\n",
    "    head=\"pod\",\n",
    "    output_dim=1,\n",
    "    loss=\"BCEWithLogitsLoss\",\n",
    "    metric_list=[\"accuracy\", \"auc\"],\n",
    ")\n",
    "\n",
    "multi_head = MultiTaskHeadConfig(\n",
    "    heads=[reg_head, cls_head],\n",
    "    head_weights=[1.0, 1.0],               # α, β  ← tune to business cost\n",
    ")\n",
    "\n",
    "# 4) Trainer & optimiser\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    max_epochs=50,\n",
    "    batch_size=2048,\n",
    "    early_stopping=\"val_loss\",\n",
    "    gpus=1,                                # 0 for CPU\n",
    "    precision=16,                          # AMP\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"AdamW\",\n",
    "    weight_decay=1e-5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595ac13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4cac9a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec56081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1.  Low‑level Dataset\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "class ParcelDataset(Dataset):\n",
    "    def __init__(self, df, num_cols, scaler):\n",
    "        self.y_eta  = df[\"total_hours_from_receiving_to_last_success_delivery\"].values.astype(\"float32\")\n",
    "        self.y_pod  = df[\"is_successful_delivery\"].values.astype(\"float32\")\n",
    "\n",
    "        # numeric → z‑score\n",
    "        self.X = scaler.transform(df[num_cols]).astype(\"float32\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_eta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.X[idx]),          # features\n",
    "            torch.tensor(self.y_eta[idx]),          # ETA (regression)\n",
    "            torch.tensor(self.y_pod[idx])           # POD success flag\n",
    "        )\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2.  Convenience factory – returns train/val DataLoaders\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def make_dataloaders(\n",
    "        file_path: str | Path,\n",
    "        num_cols: list[str],\n",
    "        batch_size: int = 10,\n",
    "        val_split: float = 0.15,\n",
    "        seed: int = 42,\n",
    "        num_workers: int = 0            # >0 if running locally with CPU cores\n",
    "):\n",
    "    df = duckdb.sql(f\"\"\"\n",
    "        SELECT * FROM '{file_path}'\n",
    "        USING SAMPLE reservoir(100 ROWS)\n",
    "        REPEATABLE (100)\n",
    "    \"\"\").df().dropna(subset=[\"total_hours_from_receiving_to_last_success_delivery\", \"is_successful_delivery\"])\n",
    "                                            \n",
    "    # train/val split (stratify by class so POD imbalance is preserved)\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=val_split,\n",
    "        stratify=df[\"is_successful_delivery\"],\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    # fit scalers *only on train*  → avoids target leakage\n",
    "    scaler  = StandardScaler().fit(train_df[num_cols])\n",
    "\n",
    "    train_ds = ParcelDataset(train_df, num_cols, scaler)\n",
    "    val_ds   = ParcelDataset(val_df,   num_cols, scaler)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
    "    val_dl   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    input_dim = train_ds.X.shape[1]    # feed into MultiTaskNet(input_dim)\n",
    "\n",
    "    return train_dl, val_dl, input_dim, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, input_dim, scaler = make_dataloaders(\n",
    "    file_path=Path(\"../data/parcel_tracking_output_data.parquet\"),\n",
    "    num_cols=parcel_df.select_dtypes(include='number').drop(columns=[\"total_hours_from_receiving_to_last_success_delivery\", \"is_successful_delivery\", \"parcel_id\"]).columns.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiTaskNet(nn.Module):\n",
    "    def __init__(self, d_in, h=128):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(d_in, h), nn.BatchNorm1d(h), nn.ReLU(),\n",
    "            nn.Linear(h, h), nn.ReLU()\n",
    "        )\n",
    "        self.reg  = nn.Sequential(nn.Linear(h, h//2), nn.ReLU(), nn.Linear(h//2, 1))\n",
    "        self.cls  = nn.Sequential(nn.Linear(h, h//2), nn.ReLU(), nn.Linear(h//2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        z   = self.shared(x)\n",
    "        eta = self.reg(z)        # hours\n",
    "        pod = self.cls(z)        # probability\n",
    "        return eta, pod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = MultiTaskNet(input_dim)\n",
    "opt    = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "for X_batch, y_eta, y_pod in train_loader:\n",
    "    eta_hat, pod_hat = model(X_batch)\n",
    "    loss = alpha * nn.functional.smooth_l1_loss(eta_hat.squeeze(), y_eta) + beta * nn.functional.binary_cross_entropy(pod_hat.squeeze(), y_pod)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    pt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fc371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
